{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d38a033",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RameshMisale\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_variance_threshold.py:111: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  self.variances_ = np.nanvar(X, axis=0)\n",
      "C:\\Users\\RameshMisale\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_variance_threshold.py:119: RuntimeWarning: All-NaN slice encountered\n",
      "  self.variances_ = np.nanmin(compare_arr, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of constant columns: 17\n",
      "Constant column: phenolics_ppm\n",
      "Unique values: [nan  0.]\n",
      "\n",
      "\n",
      "Constant column: cylinder_flag\n",
      "Unique values: [nan  0.]\n",
      "\n",
      "\n",
      "Constant column: minimum_packaging_requirements\n",
      "Unique values: [nan]\n",
      "\n",
      "\n",
      "Constant column: outbound_profile_taxes\n",
      "Unique values: [nan]\n",
      "\n",
      "\n",
      "Constant column: inbound_oubound_id_xref\n",
      "Unique values: [nan]\n",
      "\n",
      "\n",
      "Constant column: ky_report_physical_state_ind\n",
      "Unique values: [nan]\n",
      "\n",
      "\n",
      "Constant column: ky_report_onsite_ind\n",
      "Unique values: [nan]\n",
      "\n",
      "\n",
      "Constant column: contract_id\n",
      "Unique values: [nan]\n",
      "\n",
      "\n",
      "Constant column: sic_code\n",
      "Unique values: [nan]\n",
      "\n",
      "\n",
      "Constant column: pet_chem_flag\n",
      "Unique values: [nan  0.]\n",
      "\n",
      "\n",
      "Constant column: pet_chem_actual\n",
      "Unique values: [nan]\n",
      "\n",
      "\n",
      "Constant column: cokeoven_flag\n",
      "Unique values: [ 0. nan]\n",
      "\n",
      "\n",
      "Constant column: container_size_flag\n",
      "Unique values: [ 1. nan]\n",
      "\n",
      "\n",
      "Constant column: waste_type_id\n",
      "Unique values: [nan]\n",
      "\n",
      "\n",
      "Constant column: highly_toxic_flag\n",
      "Unique values: [nan  0.]\n",
      "\n",
      "\n",
      "Constant column: incin_prep_flag\n",
      "Unique values: [nan  1.]\n",
      "\n",
      "\n",
      "Constant column: no_uhcs_flag\n",
      "Unique values: [ 1. nan]\n",
      "\n",
      "\n",
      "                            feature        VIF\n",
      "0                             IsHaz  41.992835\n",
      "1                          Resubmit   1.245218\n",
      "2              outbound_profile_ind   1.218593\n",
      "3                     isRecertified   1.227366\n",
      "4                     standard_flag  32.184140\n",
      "..                              ...        ...\n",
      "79               chem_coke_pet_flag   1.282394\n",
      "80                       label_type   2.613335\n",
      "81          federal_universal_waste   1.663563\n",
      "82  generator_state_universal_waste   1.115983\n",
      "83                     revision_num   1.885647\n",
      "\n",
      "[84 rows x 2 columns]\n",
      "Random Under-sampling:\n",
      "0    6757\n",
      "1    6757\n",
      "Name: Resubmit, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "df = pd.read_excel(r\"C:\\Users\\RameshMisale\\Documents\\Profile_data.xlsx\")\n",
    "df1 = df\n",
    "df1['Resubmit'] = pd.to_datetime(df1['Resubmit'])\n",
    "df1['Resubmit'] = df1['Resubmit'].notnull().astype(int)\n",
    "columns_to_fill = ['rcra_non_haz_exempt','halogens_flag','no_reactivity_flag','layered','viscosity','odor_flag','ph_flag',\n",
    "    'flash_point_flag','boiling_point_flag','btu_per_lbs','pumpable_waste_flag','polymerizable_flag','benzene_waste_flag',\n",
    "    'voc_100_ppm','marine_pollutant_flag','origin_code','sds_attached','specific_gravity','benzene_section_flag',\n",
    "    'max_benzene_flag','benzene_water','prohibited_land_disposal','uts_waste','voc_500_ppm','specialpricing_flag',\n",
    "    'intercompany_flag','mgp_flag','pa_waste_catogory','debris','compressed_gas','analytical_ind',\n",
    "    'generatorknowledge_ind','sds_ind','formulary_attached','analytical_attached','sample_provided','mgplock_flag',\n",
    "    'naics_flag','federal_universal_waste','generator_state_universal_waste']\n",
    "df1[columns_to_fill] = df1[columns_to_fill].fillna(0, inplace=False)\n",
    "\n",
    "col = ['water_percentage', 'toc_percentage'] #filling with mean for these 2 columns\n",
    "df1[col] = df1[col].fillna(df1[col].mean(), inplace=False)\n",
    "#df1.isnull().sum()\n",
    "object_columns = df1.select_dtypes(include=['object','datetime64']).columns\n",
    "df_dropped_objects = df1.drop(object_columns, axis=1)\n",
    "# df_dropped_objects.dtypes\n",
    "\n",
    "#It will remove the zero variance features\n",
    "\n",
    "var_thres=VarianceThreshold(threshold=0)\n",
    "var_thres.fit(df_dropped_objects)\n",
    "\n",
    "constant_columns = [column for column in df_dropped_objects.columns\n",
    "                    if column not in df_dropped_objects.columns[var_thres.get_support()]]\n",
    "print(f\"Number of constant columns: {len(constant_columns)}\")\n",
    "for feature in constant_columns:\n",
    "    unique_values = df_dropped_objects[feature].unique()\n",
    "    print(f\"Constant column: {feature}\")\n",
    "    print(f\"Unique values: {unique_values}\")\n",
    "    print(\"\\n\")\n",
    "data = df_dropped_objects.drop(constant_columns,axis=1) #dropped the columns here \n",
    "\n",
    "def correlation(dataset,threshold):\n",
    "    col_corr=set()\n",
    "    corr_matrix=dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i,j]>threshold):\n",
    "                colname=corr_matrix.columns[i]\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    "\n",
    "\n",
    "corr_features=correlation(data,0.8)\n",
    "len(set(corr_features))\n",
    "\n",
    "\n",
    "data1=data.drop(corr_features,axis=1) # dropped the correlated features here\n",
    "\n",
    "\n",
    "threshold_percentage = 90 \n",
    "null_percentage = (data1.isnull().sum() / len(data1)) * 100\n",
    "columns_to_drop = null_percentage[null_percentage > threshold_percentage].index\n",
    "data1_dropped = data1.drop(columns=columns_to_drop)\n",
    "#data1_dropped.isnull().sum()\n",
    "\n",
    "data1_dropped = data1_dropped.fillna(0) #filling the null values with 0\n",
    "#data1_dropped.isnull().sum() \n",
    "\n",
    "dff = data1_dropped.drop(columns=['ReturnCount','DaysAssignReadyForGenSign','profile_id','web_profile_number',\n",
    "                                  'DaysSubmitToAssign','DaysAssignReadyForGenSign','DaysReadyForGenSignSentForGenSign',\n",
    "                                  'DaysDocSignReturnedToApproved','container_type_id','DaysInitiatedToSubmitted',\n",
    "'DaysSentForGenSignToDocSignReturned','vendor_id','ContractID','ldr_class_id','CustomerId','CollectionId',\n",
    "'HCSId','Recert','is_template_profile_flag','AssignUser_id','status_code_id','source_code_id','form_code_id',\n",
    "'management_method_code_id','outbound_profile_id','price_type_code_id','parent_profile_id','health_chemical_identity_id',\n",
    "'flammability_chemical_identity_id','reactivity_chemical_identity_id','process_code_id',\n",
    "'SalesrepID','InternalCoordinatorID','MarketDriverID','InsideSalesRepID','requested_process_code_id'],axis=1)\n",
    "dff.shape\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = dff.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(dff.values, i) for i in range(dff.shape[1])]\n",
    "print(vif_data)\n",
    "\n",
    "high_vif_columns = vif_data[vif_data[\"VIF\"] > 5][\"feature\"].tolist()\n",
    "high_vif_columns\n",
    "\n",
    "df_final = dff.drop(columns=high_vif_columns)\n",
    "df_final.shape\n",
    "\n",
    "XX = df_final.drop('Resubmit', axis='columns')\n",
    "yy= df_final['Resubmit']\n",
    "XX_train, XX_test, yy_train, yy_test = train_test_split(XX,yy, test_size=0.2,random_state=42,stratify=yy)\n",
    "\n",
    "count_0_class,count_1_class = df_final.Resubmit.value_counts()\n",
    "df_class_0 = df_final[df_final[\"Resubmit\"]==0]\n",
    "df_class_1 = df_final[df_final[\"Resubmit\"]==1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(XX,yy, test_size=0.2,random_state=15,stratify=yy)\n",
    "\n",
    "df_class_0_under = df_class_0.sample(count_1_class)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1],axis=0)\n",
    "\n",
    "print('Random Under-sampling:')\n",
    "print(df_test_under.Resubmit.value_counts())\n",
    "\n",
    "XX = df_test_under.drop('Resubmit', axis='columns')\n",
    "yy= df_test_under['Resubmit']\n",
    "XX_train, XX_test, yy_train, yy_test = train_test_split(XX,yy, test_size=0.2,random_state=42,stratify=yy)\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "# logistic_regression = LogisticRegression()\n",
    "# logistic_regression.fit(XX_train, yy_train)\n",
    "# y_pred_lr_train = logistic_regression.predict(XX_train)\n",
    "# y_pred_lr_test = logistic_regression.predict(XX_test)\n",
    "\n",
    "# # Accuracy\n",
    "# accuracy_lr_train = accuracy_score(yy_train, y_pred_lr_train)\n",
    "# accuracy_lr_test = accuracy_score(yy_test, y_pred_lr_test)\n",
    "# print(f'Logistic Regression Training Accuracy: {accuracy_lr_train}')\n",
    "# print(f'Logistic Regression Testing Accuracy: {accuracy_lr_test}')\n",
    "\n",
    "# # # classification report\n",
    "# # print(classification_report(yy_test, y_pred_lr_test))\n",
    "# # print(confusion_matrix(yy_test, y_pred_lr_test))\n",
    "\n",
    "# precision_lr_test = precision_score(yy_test, y_pred_lr_test)\n",
    "# recall_lr_test = recall_score(yy_test, y_pred_lr_test)\n",
    "# f1_lr_test = f1_score(yy_test, y_pred_lr_test)\n",
    "\n",
    "# # Display precision, recall, and f1-score\n",
    "# print(f'\\nPrecision: {precision_lr_test:.4f}')\n",
    "# print(f'Recall: {recall_lr_test:.4f}')\n",
    "# print(f'F1-Score: {f1_lr_test:.4f}')\n",
    "\n",
    "\n",
    "# import pickle\n",
    "# file_path = (r'C:\\Users\\RameshMisale\\Downloads\\Harsco_model.pkl')\n",
    "\n",
    "# # Open the file in binary write mode\n",
    "# with open(file_path, 'wb') as file:\n",
    "#     # Use pickle.dump() to serialize and save the data to the file\n",
    "#     pickle.dump(file_path, file)\n",
    "\n",
    "# print(f'Data saved to {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbe71dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8067ee3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Accuracy: 0.7469244288224957\n",
      "Random Forest Testing Accuracy: 0.7258601553829079\n",
      "\n",
      "Precision: 0.7080\n",
      "Recall: 0.7683\n",
      "F1-Score: 0.7370\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100,max_depth=10,criterion='gini')\n",
    "random_forest.fit(XX_train, yy_train)\n",
    "y_pred_rf_train = random_forest.predict(XX_train)\n",
    "y_pred_rf_test = random_forest.predict(XX_test)\n",
    "accuracy_rf_train = accuracy_score(yy_train, y_pred_rf_train)\n",
    "accuracy_rf_test = accuracy_score(yy_test, y_pred_rf_test)\n",
    "print(f'Random Forest Training Accuracy: {accuracy_rf_train}')\n",
    "print(f'Random Forest Testing Accuracy: {accuracy_rf_test}')\n",
    "# # classification report\n",
    "# print(classification_report(yy_test, y_pred_rf_test))\n",
    "# print(confusion_matrix(yy_test, y_pred_rf_test))\n",
    "\n",
    "precision_rf_test = precision_score(yy_test, y_pred_rf_test)\n",
    "recall_rf_test = recall_score(yy_test, y_pred_rf_test)\n",
    "f1_rf_test = f1_score(yy_test, y_pred_rf_test)\n",
    "\n",
    "# Display precision, recall, and f1-score\n",
    "print(f'\\nPrecision: {precision_rf_test:.4f}')\n",
    "print(f'Recall: {recall_rf_test:.4f}')\n",
    "print(f'F1-Score: {f1_rf_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c087b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "['outbound_profile_ind', 'isRecertified', 'rush_flag', 'halogens_flag', 'solid_flag', 'free_liquids_flag', 'viscosity', 'odor_flag', 'flash_point_flag', 'btu_per_lbs', 'pumpable_waste_flag', 'ApprovedTonnage', 'origin_code', 'sds_attached', 'specific_gravity', 'prohibited_land_disposal', 'voc_500_ppm', 'mgp_flag', 'national_flag', 'pa_waste_catogory', 'water_percentage', 'sds_ind', 'analytical_attached', 'label_type', 'federal_universal_waste', 'revision_num']\n",
      "\n",
      "DataFrame with Selected Features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outbound_profile_ind</th>\n",
       "      <th>isRecertified</th>\n",
       "      <th>rush_flag</th>\n",
       "      <th>halogens_flag</th>\n",
       "      <th>solid_flag</th>\n",
       "      <th>free_liquids_flag</th>\n",
       "      <th>viscosity</th>\n",
       "      <th>odor_flag</th>\n",
       "      <th>flash_point_flag</th>\n",
       "      <th>btu_per_lbs</th>\n",
       "      <th>...</th>\n",
       "      <th>voc_500_ppm</th>\n",
       "      <th>mgp_flag</th>\n",
       "      <th>national_flag</th>\n",
       "      <th>pa_waste_catogory</th>\n",
       "      <th>water_percentage</th>\n",
       "      <th>sds_ind</th>\n",
       "      <th>analytical_attached</th>\n",
       "      <th>label_type</th>\n",
       "      <th>federal_universal_waste</th>\n",
       "      <th>revision_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7709</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42946</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50829</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4288</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.529263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55311</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59337</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59364</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59367</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59370</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59377</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13514 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       outbound_profile_ind  isRecertified  rush_flag  halogens_flag  \\\n",
       "7709                      0              0        0.0            0.0   \n",
       "42946                     0              0        0.0            0.0   \n",
       "50829                     0              0        0.0            1.0   \n",
       "4288                      0              0        0.0            1.0   \n",
       "55311                     0              0        0.0            1.0   \n",
       "...                     ...            ...        ...            ...   \n",
       "59337                     0              0        0.0            0.0   \n",
       "59364                     0              0        1.0            1.0   \n",
       "59367                     0              0        1.0            1.0   \n",
       "59370                     0              0        0.0            0.0   \n",
       "59377                     0              0        0.0            0.0   \n",
       "\n",
       "       solid_flag  free_liquids_flag  viscosity  odor_flag  flash_point_flag  \\\n",
       "7709          0.0                0.0        1.0        1.0               6.0   \n",
       "42946         0.0                0.0        0.0        0.0               1.0   \n",
       "50829         0.0                0.0        0.0        0.0               6.0   \n",
       "4288          0.0                0.0        0.0        1.0               5.0   \n",
       "55311         0.0                0.0        0.0        1.0               6.0   \n",
       "...           ...                ...        ...        ...               ...   \n",
       "59337         0.0                0.0        3.0        0.0               4.0   \n",
       "59364         0.0                0.0        1.0        0.0               6.0   \n",
       "59367         0.0                0.0        1.0        0.0               6.0   \n",
       "59370         0.0                0.0        0.0        0.0               6.0   \n",
       "59377         0.0                0.0        3.0        1.0               4.0   \n",
       "\n",
       "       btu_per_lbs  ...  voc_500_ppm  mgp_flag  national_flag  \\\n",
       "7709           2.0  ...          0.0       0.0            0.0   \n",
       "42946          3.0  ...          1.0       0.0            0.0   \n",
       "50829          2.0  ...          0.0       0.0            0.0   \n",
       "4288           0.0  ...          1.0       0.0            0.0   \n",
       "55311          2.0  ...          0.0       0.0            0.0   \n",
       "...            ...  ...          ...       ...            ...   \n",
       "59337          3.0  ...          0.0       0.0            0.0   \n",
       "59364          0.0  ...          0.0       0.0            0.0   \n",
       "59367          0.0  ...          0.0       0.0            0.0   \n",
       "59370          0.0  ...          0.0       0.0            0.0   \n",
       "59377          3.0  ...          1.0       0.0            0.0   \n",
       "\n",
       "       pa_waste_catogory  water_percentage  sds_ind  analytical_attached  \\\n",
       "7709                 0.0          0.000000      0.0                  0.0   \n",
       "42946                7.0          0.000000      0.0                  0.0   \n",
       "50829                0.0          0.000000      0.0                  0.0   \n",
       "4288                 0.0         12.529263      1.0                  0.0   \n",
       "55311                0.0         10.000000      0.0                  0.0   \n",
       "...                  ...               ...      ...                  ...   \n",
       "59337                9.0         25.000000      0.0                  0.0   \n",
       "59364                0.0         80.000000      1.0                  0.0   \n",
       "59367                0.0         10.000000      1.0                  0.0   \n",
       "59370                0.0          0.000000      1.0                  0.0   \n",
       "59377                0.0         25.000000      0.0                  0.0   \n",
       "\n",
       "       label_type  federal_universal_waste  revision_num  \n",
       "7709          0.0                      0.0             0  \n",
       "42946         1.0                      0.0             0  \n",
       "50829        13.0                      0.0             7  \n",
       "4288          0.0                      1.0             0  \n",
       "55311        10.0                      0.0             0  \n",
       "...           ...                      ...           ...  \n",
       "59337         1.0                      0.0             0  \n",
       "59364         1.0                      0.0             0  \n",
       "59367         1.0                      0.0             0  \n",
       "59370         3.0                      0.0             0  \n",
       "59377         1.0                      0.0             3  \n",
       "\n",
       "[13514 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_dict = dict(zip(random_forest.feature_names_in_, [round(i, 4) for i in random_forest.feature_importances_]))\n",
    "threshold = 0.01\n",
    "selected_features = [feature for feature, importance in feature_importance_dict.items() if importance > threshold]\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)\n",
    "df_features = pd.DataFrame(data={feature: XX[feature] for feature in selected_features})\n",
    "print(\"\\nDataFrame with Selected Features:\")\n",
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e721f8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 30 Features:\n",
      "['sds_attached', 'revision_num', 'sds_ind', 'odor_flag', 'federal_universal_waste', 'label_type', 'ApprovedTonnage', 'water_percentage', 'flash_point_flag', 'solid_flag', 'isRecertified', 'free_liquids_flag', 'btu_per_lbs', 'origin_code', 'prohibited_land_disposal', 'analytical_attached', 'pa_waste_catogory', 'viscosity', 'specific_gravity', 'voc_500_ppm', 'pumpable_waste_flag', 'national_flag', 'halogens_flag', 'outbound_profile_ind', 'rush_flag', 'mgp_flag']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_importance_dict = dict(zip(random_forest.feature_names_in_, [round(i, 4) for i in random_forest.feature_importances_]))\n",
    "threshold = 0.01\n",
    "selected_features = [feature for feature, importance in feature_importance_dict.items() if importance > threshold]\n",
    "top30_features = sorted(selected_features, key=lambda x: feature_importance_dict[x], reverse=True)[:30]\n",
    "print(\"Top 30 Features:\")\n",
    "print(top30_features)\n",
    "df_top30_features = pd.DataFrame(data={feature: XX[feature] for feature in top30_features})\n",
    "# print(\"\\nDataFrame with Top 30 Features:\")\n",
    "# df_top30_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba413b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_0_class,count_1_class = df_final.Resubmit.value_counts()\n",
    "df_class_0 = df_final[df_final[\"Resubmit\"]==0]\n",
    "df_class_1 = df_final[df_final[\"Resubmit\"]==1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(XX,yy, test_size=0.2,random_state=15,stratify=yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5c0266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Under-sampling:\n",
      "0    6757\n",
      "1    6757\n",
      "Name: Resubmit, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_class_0_under = df_class_0.sample(count_1_class)\n",
    "df_top30_features = pd.concat([df_class_0_under, df_class_1],axis=0)\n",
    "\n",
    "print('Random Under-sampling:')\n",
    "print(df_test_under.Resubmit.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc2c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "569803d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: 0.7048\n",
      "Recall: 0.7528\n",
      "F1-Score: 0.7280\n",
      "Random Forest accuracy for top 30 columns: 0.7188309285978542\n"
     ]
    }
   ],
   "source": [
    "X_top30 = df_top30_features[top30_features]\n",
    "yy = df_test_under['Resubmit'] \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "XX_train, XX_test, yy_train, yy_test = train_test_split(X_top30, yy, test_size=0.2, random_state=42, stratify=yy)\n",
    "\n",
    "random_forest1 = RandomForestClassifier(n_estimators=100,max_depth=10,criterion='gini')\n",
    "random_forest1.fit(XX_train, yy_train)\n",
    "y_pred = random_forest1.predict(XX_test)\n",
    "\n",
    "accuracy = accuracy_score(yy_test, y_pred)\n",
    "classification_report_str = classification_report(yy_test, y_pred)\n",
    "confusion_mat = confusion_matrix(yy_test, y_pred)\n",
    "\n",
    "precision_rf_test = precision_score(yy_test, y_pred)\n",
    "recall_rf_test = recall_score(yy_test, y_pred)\n",
    "f1_rf_test = f1_score(yy_test, y_pred)\n",
    "\n",
    "print(f'\\nPrecision: {precision_rf_test:.4f}')\n",
    "print(f'Recall: {recall_rf_test:.4f}')\n",
    "print(f'F1-Score: {f1_rf_test:.4f}')\n",
    "print(f'Random Forest accuracy for top 30 columns: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0f802fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_path = 'random_forest1.pkl'\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(random_forest1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e79b485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\rameshmisale\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/4e/ba/ce9bd1cd4953336a0e213b29cb80bb11816f2a93de8c99f88ef0b446ad0c/scikit_learn-1.3.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached scikit_learn-1.3.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\rameshmisale\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\rameshmisale\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\rameshmisale\\anaconda3\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rameshmisale\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Using cached scikit_learn-1.3.2-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.2\n",
      "    Uninstalling scikit-learn-1.2.2:\n",
      "      Successfully uninstalled scikit-learn-1.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\RameshMisale\\\\anaconda3\\\\Lib\\\\site-packages\\\\~~learn\\\\.libs\\\\msvcp140.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model_case = joblib.load(open('random_forest.pkl', 'rb'))\n",
    "!pip install --upgrade scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cb1d54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest1.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_case = joblib.load(open('random_forest1.pkl', 'rb'))\n",
    "joblib.dump(model_case, 'random_forest1.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5812a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\RameshMisale\\\\Downloads\\\\random_forest1.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming 'model_case' is your trained model\n",
    "# Save the model to a file using joblib\n",
    "joblib.dump(model_case, r'C:\\Users\\RameshMisale\\Downloads\\random_forest1.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41bba774",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('your_file_path.csv', index=False)\n",
    "df_final.to_csv(r'C:\\Users\\RameshMisale\\Downloads\\df_final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d44663c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5c625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
